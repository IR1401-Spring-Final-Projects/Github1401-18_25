{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb744b9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb744b9d",
    "outputId": "40dc9bd7-42ed-4337-88ab-00e7c7f5d32f"
   },
   "outputs": [],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89f13c98",
   "metadata": {
    "id": "89f13c98"
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot  as plt\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65487e",
   "metadata": {
    "id": "ed65487e"
   },
   "source": [
    "## Convert Data to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d24271ce",
   "metadata": {
    "id": "d24271ce"
   },
   "outputs": [],
   "source": [
    "repos_dict = json.loads(Path('repos_dict.json').read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfad52e4",
   "metadata": {
    "id": "cfad52e4"
   },
   "outputs": [],
   "source": [
    "REPO_NAME = 'repo name'\n",
    "FILE_NAME = 'file name'\n",
    "LANG = 'language'\n",
    "CODE = 'code'\n",
    "CLASSIFICATION_PATH = 'Classification.pkl'\n",
    "TRANSFORMER_PATH = './transformer'\n",
    "valid_languages = ['Java', 'Python', 'Shell', 'C++', 'Go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b12d22",
   "metadata": {
    "id": "b7b12d22"
   },
   "outputs": [],
   "source": [
    "def get_concatanated(repo):\n",
    "    text = ''\n",
    "    for language in valid_languages:\n",
    "        path = Path(f'preprocessed_data/{repo}/{language}')\n",
    "        if not path.exists():\n",
    "            continue\n",
    "        for p in path.iterdir():\n",
    "            code = p.read_text()\n",
    "            text += code\n",
    "            text += ' '\n",
    "    return text\n",
    "\n",
    "def get_valid_test():\n",
    "    result = []\n",
    "    for repo in repos_dict:\n",
    "        if repo['language'] not in valid_languages:\n",
    "            continue\n",
    "        code = get_concatanated(repo['dir_name'])\n",
    "        result.append((repo['dir_name'], repo['url'], repo['language'], code))\n",
    "    return pd.DataFrame(result ,columns=[REPO_NAME, FILE_NAME, LANG, CODE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de461b31",
   "metadata": {
    "id": "de461b31"
   },
   "outputs": [],
   "source": [
    "repos_df = get_valid_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd198833",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd198833",
    "outputId": "5ce039e6-222c-4ec1-d079-29c919a74888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C++', 'Go', 'Java', 'Python', 'Shell'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(repos_df[LANG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a6db9ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "0a6db9ba",
    "outputId": "67afad1f-1642-49c4-bc16-5613b29fe755"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-68910d8a-c39b-4504-8577-c07e64316022\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo name</th>\n",
       "      <th>file name</th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gothinkster_realworld</td>\n",
       "      <td>https://github.com/gothinkster/realworld</td>\n",
       "      <td>Shell</td>\n",
       "      <td># set - x SCRIPTDIR = \"\" $ ( dirname \"\" ) \"\" A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nvm-sh_nvm</td>\n",
       "      <td>https://github.com/nvm-sh/nvm</td>\n",
       "      <td>Shell</td>\n",
       "      <td># find_name ( ) { find test - name \"\" &lt;&gt; \\ | ]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jgraph_drawio-desktop</td>\n",
       "      <td>https://github.com/jgraph/drawio-desktop</td>\n",
       "      <td>Shell</td>\n",
       "      <td># set - eo pipefail # SOURCE_FILE_PATH = '' # ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mathiasbynens_dotfiles</td>\n",
       "      <td>https://github.com/mathiasbynens/dotfiles</td>\n",
       "      <td>Shell</td>\n",
       "      <td># cd \"\" $ { BASH_SOURCE } \"\" ; git pull origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dwmkerr_hacker-laws</td>\n",
       "      <td>https://github.com/dwmkerr/hacker-laws</td>\n",
       "      <td>Shell</td>\n",
       "      <td># # # # version = $NUM date = $ ( date \"\" ) if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>sanic-org_sanic</td>\n",
       "      <td>https://github.com/sanic-org/sanic</td>\n",
       "      <td>Python</td>\n",
       "      <td>from __future__ import annotations from inspec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>nginx-proxy_nginx-proxy</td>\n",
       "      <td>https://github.com/nginx-proxy/nginx-proxy</td>\n",
       "      <td>Python</td>\n",
       "      <td>import pytest def test_network_web1 ( docker_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>binux_pyspider</td>\n",
       "      <td>https://github.com/binux/pyspider</td>\n",
       "      <td>Python</td>\n",
       "      <td># # # # # # import json import time from pymon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>openai_gpt-2</td>\n",
       "      <td>https://github.com/openai/gpt-2</td>\n",
       "      <td>Python</td>\n",
       "      <td>import numpy as np import tensorflow as tf fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>jhao104_proxy_pool</td>\n",
       "      <td>https://github.com/jhao104/proxy_pool</td>\n",
       "      <td>Python</td>\n",
       "      <td># \"\"\"\"\"\" __author__ = '' from fetcher . proxyF...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68910d8a-c39b-4504-8577-c07e64316022')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-68910d8a-c39b-4504-8577-c07e64316022 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-68910d8a-c39b-4504-8577-c07e64316022');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                   repo name                                   file name  \\\n",
       "0      gothinkster_realworld    https://github.com/gothinkster/realworld   \n",
       "1                 nvm-sh_nvm               https://github.com/nvm-sh/nvm   \n",
       "2      jgraph_drawio-desktop    https://github.com/jgraph/drawio-desktop   \n",
       "3     mathiasbynens_dotfiles   https://github.com/mathiasbynens/dotfiles   \n",
       "4        dwmkerr_hacker-laws      https://github.com/dwmkerr/hacker-laws   \n",
       "..                       ...                                         ...   \n",
       "145          sanic-org_sanic          https://github.com/sanic-org/sanic   \n",
       "146  nginx-proxy_nginx-proxy  https://github.com/nginx-proxy/nginx-proxy   \n",
       "147           binux_pyspider           https://github.com/binux/pyspider   \n",
       "148             openai_gpt-2             https://github.com/openai/gpt-2   \n",
       "149       jhao104_proxy_pool       https://github.com/jhao104/proxy_pool   \n",
       "\n",
       "    language                                               code  \n",
       "0      Shell  # set - x SCRIPTDIR = \"\" $ ( dirname \"\" ) \"\" A...  \n",
       "1      Shell  # find_name ( ) { find test - name \"\" <> \\ | ]...  \n",
       "2      Shell  # set - eo pipefail # SOURCE_FILE_PATH = '' # ...  \n",
       "3      Shell  # cd \"\" $ { BASH_SOURCE } \"\" ; git pull origin...  \n",
       "4      Shell  # # # # version = $NUM date = $ ( date \"\" ) if...  \n",
       "..       ...                                                ...  \n",
       "145   Python  from __future__ import annotations from inspec...  \n",
       "146   Python  import pytest def test_network_web1 ( docker_c...  \n",
       "147   Python  # # # # # # import json import time from pymon...  \n",
       "148   Python  import numpy as np import tensorflow as tf fro...  \n",
       "149   Python  # \"\"\"\"\"\" __author__ = '' from fetcher . proxyF...  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8007aa2",
   "metadata": {
    "id": "b8007aa2"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f137131",
   "metadata": {
    "id": "7f137131"
   },
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def get_true_labels(self):\n",
    "        true_labels = [valid_languages.index(language) for language in self.df[LANG].tolist()]\n",
    "        return np.array(true_labels)\n",
    "    \n",
    "    def get_code(self):\n",
    "        return self.df[CODE].tolist()\n",
    "    \n",
    "    def get_labeled_data(self):\n",
    "        return self.get_code(), self.get_true_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b67fcd1d",
   "metadata": {
    "id": "b67fcd1d"
   },
   "outputs": [],
   "source": [
    "repos_data = Data(repos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1be23b",
   "metadata": {
    "id": "3e1be23b"
   },
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13f720c0",
   "metadata": {
    "id": "13f720c0"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = repos_data.get_labeled_data()\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929669f",
   "metadata": {
    "id": "9929669f"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adb194cb",
   "metadata": {
    "id": "adb194cb"
   },
   "outputs": [],
   "source": [
    "class Classification():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            ngram_range=(1,2),\n",
    "            max_df=0.9,\n",
    "            min_df=0.1,\n",
    "            stop_words=None,\n",
    "            norm='l2'\n",
    "        )\n",
    "        \n",
    "    def train(self, X_train, y_train):\n",
    "        self.y_train = y_train\n",
    "        self.doc_term_mat = self.vectorizer.fit_transform(X_train)\n",
    "        self.clf = LogisticRegression(random_state=0, multi_class='multinomial').fit(self.doc_term_mat, y_train)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        vectorize_X = self.get_vectorized(X)\n",
    "        return self.clf.predict(vectorize_X)\n",
    "    \n",
    "    def predict_code(self, code):\n",
    "        preprocessed_code = [preprocess(code)]\n",
    "        index = self.predict(preprocessed_code)[0]\n",
    "        language = valid_languages[index]\n",
    "        return language\n",
    "    \n",
    "    def get_vectorized(self, X):\n",
    "        vectorize_X = self.vectorizer.transform(X)\n",
    "        return vectorize_X\n",
    "    \n",
    "    def get_accuracy(self, X, y):\n",
    "        vectorize_X = self.get_vectorized(X)\n",
    "        return self.clf.score(vectorize_X, y)\n",
    "    \n",
    "    def get_f1_score(self, X, y, average):\n",
    "        predicted = self.predict(X)\n",
    "        return f1_score(y, predicted, average=average)\n",
    "    \n",
    "    def get_confusion_matrix(self, X, y):\n",
    "        predicted = self.predict(X)\n",
    "        return confusion_matrix(y, predicted, labels=list(range(len(valid_languages))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0a0d30f",
   "metadata": {
    "id": "d0a0d30f"
   },
   "outputs": [],
   "source": [
    "classification = Classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb276b75",
   "metadata": {
    "id": "fb276b75"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6446e2f",
   "metadata": {
    "id": "e6446e2f"
   },
   "outputs": [],
   "source": [
    "classification.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4299f052",
   "metadata": {
    "id": "4299f052"
   },
   "source": [
    "## Calculate f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76913567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76913567",
    "outputId": "54af3708-15f0-41af-b44e-d036e86aa2f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.938095238095238"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = classification.get_f1_score(X_val_test, y_val_test, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c639d27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c639d27",
    "outputId": "0414dcd1-def8-4b90-85d8-5dc119902ae7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro = classification.get_f1_score(X_val_test, y_val_test, average='micro')\n",
    "f1_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473022a",
   "metadata": {
    "id": "c473022a"
   },
   "source": [
    "As you see our f1-score both in macro case and micro case is more than 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc23c16",
   "metadata": {
    "id": "dcc23c16"
   },
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57bc7dba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57bc7dba",
    "outputId": "6b47a606-ad8e-4491-cd35-90a7f1773f4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = classification.get_accuracy(X_val_test, y_val_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a0c9c",
   "metadata": {
    "id": "af3a0c9c"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0675a0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0675a0d",
    "outputId": "737cf080-b2d5-49bf-eabf-dfe307c38cad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, 0, 0],\n",
       "       [0, 5, 0, 0, 0],\n",
       "       [0, 0, 5, 0, 0],\n",
       "       [0, 0, 2, 6, 0],\n",
       "       [0, 0, 0, 0, 6]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_confusion_matrix = classification.get_confusion_matrix(X_val_test, y_val_test)\n",
    "classification_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acbd2a8",
   "metadata": {
    "id": "0acbd2a8"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "G7GaSxBphLvt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7GaSxBphLvt",
    "outputId": "6b91f027-28d0-4ed0-e7fd-b36bee977a1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ei83xQF9izTI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ei83xQF9izTI",
    "outputId": "5102da09-6550-4a08-a0bd-5d94f15c476e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5, problem_type=\"single_label_classification\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fsWYEJEzmD5x",
   "metadata": {
    "id": "fsWYEJEzmD5x"
   },
   "outputs": [],
   "source": [
    "train_encoding = tokenizer(X_train, truncation=True, padding=True)\n",
    "val_encoding = tokenizer(X_val, truncation=True, padding=True)\n",
    "test_encoding = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Et7xLkuV2i9c",
   "metadata": {
    "id": "Et7xLkuV2i9c"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9wXXlfYEk17N",
   "metadata": {
    "id": "9wXXlfYEk17N"
   },
   "outputs": [],
   "source": [
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, encoding, labels):\n",
    "        self.encoding = encoding\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(value[idx]) for key, value in self.encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ggOhjNpYimkV",
   "metadata": {
    "id": "ggOhjNpYimkV"
   },
   "outputs": [],
   "source": [
    "train_dataset = LanguageDataset(train_encoding, y_train)\n",
    "val_dataset = LanguageDataset(val_encoding, y_val)\n",
    "test_dataset = LanguageDataset(test_encoding, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KWjvCkEY2mAz",
   "metadata": {
    "id": "KWjvCkEY2mAz"
   },
   "source": [
    "## Transformer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "JWvJX_oLtHbG",
   "metadata": {
    "id": "JWvJX_oLtHbG"
   },
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model =  model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def set_trainer(\n",
    "        self, \n",
    "        train_dataset, \n",
    "        val_dataset, \n",
    "        per_device_train_batch_size=10, \n",
    "        per_device_eval_batch_size=5, \n",
    "        learning_rate=3e-05,\n",
    "        weight_decay=0.0,\n",
    "        adam_beta1=0.93,\n",
    "        adam_beta2=0.999,\n",
    "        adam_epsilon=1e-08,\n",
    "        num_train_epochs=100,\n",
    "        warmup_steps=100,\n",
    "        logging_steps=20,\n",
    "        save_steps=2000,\n",
    "        ):\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = './results',\n",
    "            do_train=True,\n",
    "            do_eval=True,\n",
    "            per_device_train_batch_size=per_device_train_batch_size,\n",
    "            per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            adam_beta1=adam_beta1,\n",
    "            adam_beta2=adam_beta2,\n",
    "            adam_epsilon=adam_epsilon,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            warmup_steps=warmup_steps,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=logging_steps,\n",
    "            save_steps=save_steps,\n",
    "        )\n",
    "\n",
    "        self.trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "    )\n",
    "        \n",
    "    def train(self):\n",
    "        self.trainer.train()\n",
    "\n",
    "    def predict(self, X, dataset=True):\n",
    "        self.model.eval()\n",
    "\n",
    "        if dataset:\n",
    "            X_dataloader = DataLoader(dataset=X, batch_size=5, shuffle=False)\n",
    "            predicted_labels = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs in X_dataloader:\n",
    "                    inputs_cuda = {key: value.to(device) for key, value in inputs.items()}\n",
    "                    logits = self.model(**inputs_cuda).logits\n",
    "                    predicted_class_id = logits.argmax(dim=1)\n",
    "                    predicted_labels += [self.model.config.id2label[index.item()] for index in predicted_class_id]\n",
    "            return np.array([int(x.replace('LABEL_', '')) for x in predicted_labels])\n",
    "\n",
    "        else:\n",
    "            inputs = self.tokenizer(X, truncation=True, padding=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs_cuda = {key: value.to(device) for key, value in inputs.items()}\n",
    "                logits = self.model(**inputs_cuda).logits\n",
    "\n",
    "            predicted_class_id = logits.argmax().item()\n",
    "            return self.model.config.id2label[predicted_class_id]\n",
    "\n",
    "    def get_accuracy(self, X, y):\n",
    "        predicted = self.predict(X)\n",
    "        return np.mean(predicted == y)\n",
    "\n",
    "    def get_f1_score(self, X, y, average):\n",
    "        predicted = self.predict(X)\n",
    "        return f1_score(y, predicted, average=average)\n",
    "    \n",
    "    def get_confusion_matrix(self, X, y):\n",
    "        predicted = self.predict(X)\n",
    "        return confusion_matrix(y, predicted, labels=list(range(len(valid_languages))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aByOpP2c5tSk",
   "metadata": {
    "id": "aByOpP2c5tSk"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sX-yX31u2sMu",
   "metadata": {
    "id": "sX-yX31u2sMu"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ctdKtWZj2qEi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ctdKtWZj2qEi",
    "outputId": "934541b7-e551-4424-c875-59272b43b94b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 120\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 10\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 10\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1200 10:04, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.345300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.609200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.416200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.124500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.142200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.116600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.146900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.119400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.124300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.124200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.112200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.129200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.130200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.113400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.094300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.135600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.133200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.130900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.set_trainer(train_dataset, val_dataset)\n",
    "transformer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y6rAEwED282o",
   "metadata": {
    "id": "y6rAEwED282o"
   },
   "source": [
    "## Calculate f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "_hP7rs_k29qf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hP7rs_k29qf",
    "outputId": "45ffffe3-ac70-487d-d350-9b97084044e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551515151515151"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = transformer.get_f1_score(test_dataset, y_test, average='macro')\n",
    "f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "qaxJ6qRw3Dv6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaxJ6qRw3Dv6",
    "outputId": "46d3cbae-9f52-4fa9-abb9-0e352ac0e927"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8000000000000002"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_micro = transformer.get_f1_score(test_dataset, y_test, average='micro')\n",
    "f1_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GnKzdLTw3Gbz",
   "metadata": {
    "id": "GnKzdLTw3Gbz"
   },
   "source": [
    "## Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cq9-34b73S4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cq9-34b73S4b",
    "outputId": "bbd3525c-4f9c-442c-f4b4-d589a8e1ad6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = transformer.get_accuracy(test_dataset, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9qLxbZWa3aRU",
   "metadata": {
    "id": "9qLxbZWa3aRU"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88oK7mnT3bM5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88oK7mnT3bM5",
    "outputId": "7be4c394-e6c6-413e-b67e-dc37019a9a04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 3]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_confusion_matrix = transformer.get_confusion_matrix(test_dataset, y_test)\n",
    "transformer_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TLV7JqCl190W",
   "metadata": {
    "id": "TLV7JqCl190W"
   },
   "source": [
    "## Save and Load Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "iEiHCiwS1-s6",
   "metadata": {
    "id": "iEiHCiwS1-s6"
   },
   "outputs": [],
   "source": [
    "def save_object(obj, file_name):\n",
    "    with open(file_name, 'wb') as file:\n",
    "        pickle.dump(obj, file, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "def load_object(file_name):\n",
    "    with open(file_name, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4Vbp6-3o2C5a",
   "metadata": {
    "id": "4Vbp6-3o2C5a"
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3eac2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btRhVQqh2F8J",
    "outputId": "f4c7bfe0-c8b5-4ad9-dab6-31f68ffc3c46"
   },
   "outputs": [],
   "source": [
    "save_object(classification, CLASSIFICATION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "btRhVQqh2F8J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btRhVQqh2F8J",
    "outputId": "f4c7bfe0-c8b5-4ad9-dab6-31f68ffc3c46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./transformer/tokenizer_config.json\n",
      "Special tokens file saved in ./transformer/special_tokens_map.json\n",
      "Configuration saved in ./transformer/config.json\n",
      "Model weights saved in ./transformer/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "transformer.tokenizer.save_pretrained(TRANSFORMER_PATH)\n",
    "transformer.model.save_pretrained(TRANSFORMER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HfFItJmI2V5B",
   "metadata": {
    "id": "HfFItJmI2V5B"
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585bf92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11Tby1bM2YBp",
    "outputId": "e3db06f4-5668-4909-b594-bec7ec5f957c"
   },
   "outputs": [],
   "source": [
    "classification = load_object(CLASSIFICATION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11Tby1bM2YBp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11Tby1bM2YBp",
    "outputId": "e3db06f4-5668-4909-b594-bec7ec5f957c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./transformer/added_tokens.json. We won't load it.\n",
      "loading file ./transformer/vocab.txt\n",
      "loading file None\n",
      "loading file ./transformer/special_tokens_map.json\n",
      "loading file ./transformer/tokenizer_config.json\n",
      "loading configuration file ./transformer/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./transformer/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./transformer.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(TRANSFORMER_PATH)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(TRANSFORMER_PATH, num_labels=5, problem_type=\"single_label_classification\").to(device)\n",
    "transformer = Transformer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd285fe5",
   "metadata": {
    "id": "dd285fe5"
   },
   "source": [
    "## Technical Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454639f5",
   "metadata": {},
   "source": [
    "<div dir = \"rtl\">\n",
    "    ابتدا تمامی اطلاعات بدست آمده از repositoryها را در یک dataframe می‌ریزیم.\n",
    "    سپس برای استفاده بهتر از این dataframe، آن را به صورت یک کلاس Data در می‌آوریم.\n",
    "    سپس داده‌ها را به دسته‌های train، validation و test تقسیم می‌کنیم.\n",
    "    در قسمت دسته‌بندی کلاس Classification را می‌سازیم. با استفاده از tf-idf کد ها را به فضای برداری می‌بریم. سپس با استفاده از logistic regression مدل را train می‌کنیم. \n",
    "    در قسمت transformer از DistilBERT-base-uncased transformer استفاده می‌کنیم. داکیومنتیشن مربوط به این transformer در این <a href=\"https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\">لینک</a> قرار دارد. \n",
    "    سپس امبدینگ مربوط به داده‌های هر دسته را بدست می‌آوریم.\n",
    "    سپس برای هر دسته یک Dataset می‌سازیم تا بتوانیم بهتر از آنها استفاده کنیم.\n",
    "    در ادامه نیز کلاس Transformer را می‌سازیم. \n",
    "    سپس بعد از ساختن object کلاس Transformer، آن را در 100 epoch آموزش می‌دهیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fc1bb",
   "metadata": {
    "id": "8e8fc1bb"
   },
   "source": [
    "<div dir = \"rtl\">\n",
    "    تمام توضیحات چگونگی crawling و دیگر مواردی که در بخش clustring نیز انجام شده‌اند در notebook مخصوص clustering قابل مشاهده است.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classification.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
